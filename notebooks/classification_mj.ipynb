{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with softmax and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>building</td>\n",
       "      <td>The earthquake led to the collapse of 72 build...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>building</td>\n",
       "      <td>Collapsed reinforced concrete buildings were l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>building</td>\n",
       "      <td>They show photos of three collapsed buildings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>building</td>\n",
       "      <td>Specifically, it shows the photo of a 6-story ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>building</td>\n",
       "      <td>There is no particular plan or elevation irreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>building</td>\n",
       "      <td>In that regard, research should continue to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>building</td>\n",
       "      <td>A 10-story school building in Manila (Emilio A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>building</td>\n",
       "      <td>Soil liquefaction underneath the building was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>building</td>\n",
       "      <td>This tilting demonstrates the effect of far fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>building</td>\n",
       "      <td>Furthermore, the structure being a school buil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence\n",
       "0   building  The earthquake led to the collapse of 72 build...\n",
       "1   building  Collapsed reinforced concrete buildings were l...\n",
       "2   building     They show photos of three collapsed buildings.\n",
       "3   building  Specifically, it shows the photo of a 6-story ...\n",
       "4   building  There is no particular plan or elevation irreg...\n",
       "..       ...                                                ...\n",
       "62  building  In that regard, research should continue to de...\n",
       "63  building  A 10-story school building in Manila (Emilio A...\n",
       "64  building  Soil liquefaction underneath the building was ...\n",
       "65  building  This tilting demonstrates the effect of far fi...\n",
       "66  building  Furthermore, the structure being a school buil...\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == \"building\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Lemmatize (~Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt_lst):   \n",
    "    def clean_text(text, remove_stopwords = True):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'\\<a href', ' ', text)\n",
    "        text = re.sub(r'&amp;', '', text) \n",
    "        text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "        text = re.sub(r'<br />', ' ', text)\n",
    "        text = re.sub(r'\\'', ' ', text)\n",
    "        if remove_stopwords:\n",
    "            text = text.split()\n",
    "            stops = set(stopwords.words(\"english\"))\n",
    "            text = [w for w in text if not w in stops]\n",
    "            text = \" \".join(text)\n",
    "        return nltk.WordPunctTokenizer().tokenize(text)\n",
    "    return list(map(clean_text, txt_lst))\n",
    "\n",
    "def lemmatize(txt_lst):\n",
    "    lemm = nltk.stem.WordNetLemmatizer()\n",
    "    return list(map(lambda word: list(map(lemm.lemmatize, word)),\n",
    "                    txt_lst))\n",
    "\n",
    "df['cleaned'] = clean(df['sentence'])\n",
    "df['lemmatized'] = lemmatize(df['cleaned'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize BOW and Split for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validate_data = sklearn.model_selection.train_test_split(df, train_size = 0.65, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_converter = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "\n",
    "x_train = bow_converter.fit_transform(train_data['lemmatized'])\n",
    "x_validate = bow_converter.transform(validate_data['lemmatized'])\n",
    "\n",
    "y_train = train_data[\"label\"]\n",
    "y_validate = validate_data[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  0.717391304347826\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C=1).fit(x_train, y_train)\n",
    "train_score = model_lr.score(x_train, y_train)\n",
    "test_score = model_lr.score(x_validate, y_validate)\n",
    "print('Train Score: ', train_score)\n",
    "print('Test Score: ', test_score)\n",
    "\n",
    "max_test_score = 0\n",
    "\n",
    "\n",
    "# w/ Elastic Penalty\n",
    "\n",
    "# for C in np.linspace(0, 3, 20):\n",
    "#     for r in np.linspace(0, 1, 20):\n",
    "#         model = LogisticRegression(penalty='elasticnet', \n",
    "#                                    C=2, solver='saga', l1_ratio=r).fit(x_train, y_train)\n",
    "#         test_score = model.score(x_test, y_test)\n",
    "#         if test_score > max_test_score:\n",
    "#             max_test_score = test_score\n",
    "\n",
    "# print('Test Score: ', train_score)\n",
    "# print('Test Score: ', max_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22,  0,  4],\n",
       "       [ 4,  3,  3],\n",
       "       [ 2,  0,  8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_lr.predict(x_validate)\n",
    "confusion_matrix(y_validate, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Test Score:  0.7391304347826086\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.LinearSVC()\n",
    "model_svm.fit(x_train, y_train)\n",
    "train_score = model_svm.score(x_train, y_train)\n",
    "test_score = model_svm.score(x_validate, y_validate)\n",
    "print('Train Score: ', train_score)\n",
    "print('Test Score: ', test_score)\n",
    "\n",
    "max_test_score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21,  0,  5],\n",
       "       [ 2,  5,  3],\n",
       "       [ 2,  0,  8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_svm.predict(x_validate)\n",
    "confusion_matrix(y_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_albania = pd.read_csv('Albania.csv')\n",
    "\n",
    "df_albania['cleaned'] = clean(df_albania['Sentence'])\n",
    "df_albania['lemmatized'] = lemmatize(df_albania['cleaned'])  \n",
    "\n",
    "x_test = bow_converter.transform(df_albania['lemmatized'])\n",
    "\n",
    "df_albania[\"SVM\"] = model_svm.predict(x_test)\n",
    "df_albania[\"Logistic Regression\"] = model_lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_building = [\"building\", \"house\", \"apartment\", \"hotel\", \n",
    "                 \"school\", \"damage\", \n",
    "                 [\"hospital\", \"damage\"], \n",
    "                 [\"school\", \"damage\"], \n",
    "                 [\"hospital\", \"collapse\"],\n",
    "                 [\"school\", \"failure\"],\n",
    "                 [\"school\", \"damage\"],\n",
    "                 [\"school\", \"collapse\"]]\n",
    "\n",
    "queries_infra = [\"bridge\", \"highway\", \"road\", \"dam\", \"refinery\", \"airport\", \n",
    "              \"power plant\", \"rail\", \"tunnel\", \"port\", \"substation\", \n",
    "              \"subway\",\n",
    "              [\"transmission\", \"tower\"],\n",
    "              [\"cell\", \"tower\"],\n",
    "              [\"pipeline\", \"damage\"], \n",
    "              [\"pipeline\", \"failure\"], \n",
    "              [\"pipeline\", \"collapse\"]]\n",
    "\n",
    "queries_resil = [\"economic\", \"economy\", \"population\", \"casualty\", \n",
    "              \"injury\", \"electricity\", \"water\", \"telecommunication\", \n",
    "              \"phone\", \"power outage\", \"transportation\", \"service\", \n",
    "              \"services\", \"internet\", \"displaced\", \"homeless\",\n",
    "              \"builidng\", \"school\", \"gas\"]\n",
    "\n",
    "def query_count(sent, queries):\n",
    "    count = 0\n",
    "    for query in queries:\n",
    "        if isinstance(query, list):\n",
    "            if all([word in sent for word in query]):\n",
    "                count += 1\n",
    "        else:\n",
    "            if query in sent:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def model_query(sentences):\n",
    "    y = []\n",
    "    labels = [\"building\", \"infrastructure\", \"resilience\"]\n",
    "    for s in sentences:\n",
    "        count_building = query_count(s, queries_building)\n",
    "        count_infra = query_count(s, queries_infra)\n",
    "        count_resil = query_count(s, queries_resil)\n",
    "        \n",
    "        counts = [count_building,\n",
    "                  count_infra, \n",
    "                  count_resil]\n",
    "        \n",
    "        if max(counts) == 0:\n",
    "            y.append(\"other\")\n",
    "        else:\n",
    "            imax = np.argmax(counts)\n",
    "            y.append(labels[imax])\n",
    "    return y\n",
    "\n",
    "df_albania[\"Keyword Search\"] = model_query(df_albania['Sentence'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albania = df_albania.drop(columns=['cleaned', 'lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albania.to_csv(\"dataset_albania.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}